{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третье домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`task 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_lowercase\n",
    "ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ' абвгдеёжзийклмнопрстуфхцчшщъыьэюя' # + ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./corpora/WarAndPeace.txt', 'r') as f:\n",
    "    text = f.readlines()\n",
    "    text = str.lower(\" \".join(text))\n",
    "    text = \"\".join([i for i in text if i in alphabet])\n",
    "    text = re.sub(r\"\\W+\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    text = re.sub(r\"ё\", \"е\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' война и мир самый известный роман льва николаевича толстого как никакое другое произведение писателя отражает глубину его мироощущения и философииэта книга из разряда вечных потому что она обо всем о жизни и смерти о любви и чести о мужестве и героизме о славе и подвиге о войне и мирепервый том знакомит с высшим обществом россии века показаны взаимоотношения между родителями и детьми в семье ростовых сватовство у болконских интриги у безуховых вечера в салоне фрейлины апшерер балы в москве и петербурге лев николаевич толстойчасть первая часть орая часть третья лев николаевич толстой война и мир том часть первая е поместья мой верный раб ну что князь генуа и лукка стали не больше как поместьями фамилии бонапарте нет я вас предупреждаю если вы мне не скажете что у нас война если вы еще позволите себе защищать все гадости все ужасы этого антихриста право я верю что он антихрист я вас больше не знаю вы уж не друг мой вы уж не мой верный раб как вы говорите ну здравствуйте здравствуйте я вижу что я вас пугаю садитесь и рассказывайте так говорила в июле года известная анна павловна шерер фрейлина и приближенная императрицы марии феодоровны встречая важного и чиновного князя василия первого приехавшего на ее вечер анна павловна кашляла несколько дней у нее был грипп как она говорила грипп был тогда новое слово употреблявшееся только редкими в записочках разосланных утром с красным лакеем было написано без различия во всех или если вас граф или князь нет в виду ничего лучшего и если'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642495"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counter_unigram(text):\n",
    "    counter = Counter()\n",
    "    for symbol in text:\n",
    "        counter[symbol] += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 103408), ('о', 61282), ('а', 45209), ('е', 42950), ('и', 35838)]\n"
     ]
    }
   ],
   "source": [
    "wp_counter = get_counter_unigram(text)\n",
    "print(wp_counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'о', 'а', 'е', 'и']\n"
     ]
    }
   ],
   "source": [
    "wp_sorted = [i[0] for i in wp_counter.most_common(999)]\n",
    "print(wp_sorted[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_encryption(tokens):\n",
    "    encrypted = tokens.copy()\n",
    "    random.shuffle(encrypted)\n",
    "    encoder = dict(zip(tokens, encrypted))\n",
    "    return encoder\n",
    "\n",
    "def encrypt(text, encoder):\n",
    "    encrypted = str.translate(text, {ord(k): ord(v) for k, v in encoder.items()})\n",
    "    return encrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 'ш', 'в': 'ъ', 'о': 'у', 'й': 'э', 'н': 'и', 'а': 'п', 'и': 'к', 'м': 'ц', 'р': 'о', 'с': 'ф', 'ы': 'н', 'з': 'м', 'е': 'р', 'т': 'т', 'л': 'ж', 'ь': 'е', 'к': 'ю', 'ч': 'й', 'г': 'я', 'д': 'д', 'у': 'ч', 'п': 'а', 'я': 'с', 'ж': 'ь', 'б': 'в', 'щ': 'ы', 'ф': 'щ', 'э': ' ', 'х': 'б', 'ю': 'г', 'ш': 'з', 'ц': 'х', 'ъ': 'л'}\n"
     ]
    }
   ],
   "source": [
    "tokens = list(wp_counter.keys())\n",
    "encoder = generate_random_encryption(tokens)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(sample_encoded, get_counter, text):\n",
    "    \n",
    "    # считаем частоты в большом тексте\n",
    "    train_counter = get_counter(text)\n",
    "    train_keys_sorted = [i[0] for i in train_counter.most_common(999)]\n",
    "\n",
    "    # считаем частоты в закодированном сообщении\n",
    "    enc_counter = get_counter(sample_encoded)\n",
    "    enc_keys_sorted = [i[0] for i in enc_counter.most_common(999)]\n",
    "\n",
    "    # маппим друг на друга\n",
    "    decoder = dict(zip(train_keys_sorted, enc_keys_sorted))\n",
    "    \n",
    "    return decoder\n",
    "\n",
    "\n",
    "def decode(sample_encoded, decoder):\n",
    "    decoded_text = str.translate(sample_encoded, {ord(v): ord(k) for k, v in decoder.items()})\n",
    "    return decoded_text\n",
    "\n",
    "\n",
    "def char_accuracy(original_text, decoded_text):\n",
    "    hit, n = 0, 0\n",
    "    for orig_char, decoded_char in zip(original_text, decoded_text):\n",
    "        if orig_char == decoded_char:\n",
    "            hit += 1\n",
    "        n += 1\n",
    "    return hit / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "\n",
      "началось сражение с фронта но в дюренштейне где я находился войско начало атаку в часу вечера сказал болконский оживляясь и при этом случае предполагая что ему удастся представить уже готовое в его голове правдивое описание всего того что он знал и видел но император улыбнулся и перебил его сколько миль откуда и докуда ваше величество от дюренштейна до кремса три с половиною мили ваше величество французы оставили левый берег как доносили лазутчики в ночь на плотах переправились последние достаточно ли фуража в кремсе фураж не был доставлен в том количестве император перебил его в котором часу убит генерал шмит в семь часов кажется в часов очень печально очень печально император сказал что он\n"
     ]
    }
   ],
   "source": [
    "sample = text[333333:333333 + 700]\n",
    "print('Исходный текст:\\n')\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Закодированное сообщение:\n",
      "\n",
      "вчхчесбюдбочйрвгрдбдзосвачдвсдъднкорвшартврджнрдщдвчьснгебщдъстбэсдвчхчесдчачэмдъдхчбмдърхрочдбэч чедлсеэсвбэгтдсйгъещщбюдгдяогдфасцдбемхчрдяорнясечжчщдхасдрцмдмнчбабщдяорнбачъгаюдмйрджсасъсрдъдржсджсесърдяочънгъсрдсягбчвгрдъбржсдасжсдхасдсвд вчедгдъгнредвсдгцярочасодмеулвмебщдгдярорлгедржсдбэсеюэсдцгеюдсаэмнчдгднсэмнчдъчшрдърегхрбаъсдсаднкорвшартвчднсдэорцбчдаогдбдясесъгвскдцгегдъчшрдърегхрбаъсдзочвым удсбачъгегдеръутдлрорждэчэднсвсбгегдеч махгэгдъдвсхюдвчдяесачьдяроряочъгегбюдясбернвгрднсбачасхвсдегдзмочйчдъдэорцбрдзмочйдврдлуеднсбачъервдъдасцдэсегхрбаърдгцярочасодярорлгедржсдъдэсасосцдхчбмдмлгаджрврочедшцгадъдбрцюдхчбсъдэчйрабщдъдхчбсъдсхрвюдярхчеювсдсхрвюдярхчеювсдгцярочасодбэч чедхасдсв\n"
     ]
    }
   ],
   "source": [
    "sample_encoded = encrypt(sample, encoder)\n",
    "print('Закодированное сообщение:\\n')\n",
    "print(sample_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Декодированное сообщение:\n",
      "\n",
      "векенотг требавиа т шровсе во л уюравчсайва ьуа ы вецоуинты лойтдо векено еседп л кетп лакаре тдежен зондовтдий обилныытг и мри эсоя тнпкеа мраумонеьеы ксо аяп пуетсты мраутселисг пба ьосолоа л аьо ьонола мрелуилоа омитевиа лтаьо соьо ксо ов жвен и лиуан во иямаресор пнхзвпнты и маразин аьо тдонгдо яинг осдпуе и уодпуе леча ланикатсло ос уюравчсайве уо драяте сри т моноливою яини леча ланикатсло шревщпжх отселини налхй зараь дед уовотини нежпскиди л вокг ве мносец марамрелинитг мотнаувиа уотсесокво ни шпребе л драята шпреб ва зхн уотселнав л соя доникатсла иямаресор маразин аьо л досороя кетп пзис ьаварен чяис л таяг кетол дебасты л кетол окавг макенгво окавг макенгво иямаресор тдежен ксо ов\n"
     ]
    }
   ],
   "source": [
    "decoder = get_decoder(sample_encoded, get_counter_unigram, text)\n",
    "decoded_text = decode(sample_encoded, decoder)\n",
    "print('Декодированное сообщение:\\n')\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность:\n",
      "\n",
      "36.29%\n"
     ]
    }
   ],
   "source": [
    "print('Точность:\\n')\n",
    "print(f'{char_accuracy(sample, decoded_text):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитать невозможно, но что если взять больше семпл?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size:     200     accuracy: 22%\n",
      "sample_size:     500     accuracy: 38%\n",
      "sample_size:    1500     accuracy: 45%\n",
      "sample_size:    3000     accuracy: 51%\n",
      "sample_size:    5000     accuracy: 64%\n",
      "sample_size:   10000     accuracy: 66%\n",
      "sample_size:   30000     accuracy: 82%\n",
      "sample_size:   50000     accuracy: 69%\n",
      "sample_size:  100000     accuracy: 70%\n",
      "sample_size:  200000     accuracy: 91%\n",
      "sample_size:  400000     accuracy: 92%\n",
      "sample_size:  642495     accuracy: 92%\n"
     ]
    }
   ],
   "source": [
    "for sample_size in [200, 500, 1500, 3000, 5000, 10000, 30000, 50000, 100000, 200000, 400000, 642495]:\n",
    "    \n",
    "    # encode\n",
    "    start_point = 123456\n",
    "    sample = text[start_point : start_point + sample_size]\n",
    "    sample_encoded = encrypt(sample, encoder)\n",
    "\n",
    "    # decode\n",
    "    decoder = get_decoder(sample_encoded, get_counter_unigram, text)\n",
    "    decoded_text = decode(sample_encoded, decoder)\n",
    "    \n",
    "    # metrics\n",
    "    char_acc = char_accuracy(sample, decoded_text)\n",
    "    print(f\"sample_size: {sample_size:>7}     accuracy: {char_acc:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда размер текста более 5000 символов достигаем какую-никакую точность. На 30000 символах можно практически читать тексты. (Правда все сильно зависит от семла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`task 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counter_bigram(text):\n",
    "    counter = Counter()\n",
    "    for idx, symbol in enumerate(text[:-1]):\n",
    "        counter[text[idx] + text[idx + 1]] += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('о ', 13316), ('и ', 11397), ('а ', 10596), ('е ', 10441), (' с', 9863), (' п', 9767), (' в', 9612), (' н', 9347), ('то', 8491), (' о', 7683), ('я ', 7096), (' к', 7045), (' и', 6834), ('ст', 6671), ('ь ', 6603)]\n"
     ]
    }
   ],
   "source": [
    "wp_counter_bigram = get_counter_bigram(text)\n",
    "print(wp_counter_bigram.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['о ', 'и ', 'а ', 'е ', ' с', ' п', ' в', ' н', 'то', ' о', 'я ', ' к', ' и', 'ст', 'ь ']\n"
     ]
    }
   ],
   "source": [
    "wp_sorted_bigram = [i[0] for i in wp_counter_bigram.most_common(999)]\n",
    "print(wp_sorted_bigram[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bigram(sample_encoded, decoder):\n",
    "    \"\"\" Декодирование на основе биграмм \"\"\"\n",
    "    inversed_decoder = {v: k for k, v in decoder.items()}\n",
    "    decoded_text = ['.'] * len(sample_encoded)\n",
    "    for idx, symbol in enumerate(sample_encoded[:-1]):\n",
    "        bigram = (sample_encoded[idx] + sample_encoded[idx + 1])\n",
    "        decoded_text[idx] = inversed_decoder[bigram][0]\n",
    "        decoded_text[idx + 1] = inversed_decoder[bigram][1]\n",
    "    decoded_text = ''.join(decoded_text)\n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "\n",
      "началось сражение с фронта но в дюренштейне где я находился войско начало атаку в часу вечера сказал болконский оживляясь и при этом случае предполагая что ему удастся представить уже готовое в его голове правдивое описание всего того что он знал и видел но император улыбнулся и перебил его сколько миль откуда и докуда ваше величество от дюренштейна до кремса три с половиною мили ваше величество французы оставили левый берег как доносили лазутчики в ночь на плотах переправились последние достаточно ли фуража в кремсе фураж не был доставлен в том количестве император перебил его в котором часу убит генерал шмит в семь часов кажется в часов очень печально очень печально император сказал что он\n"
     ]
    }
   ],
   "source": [
    "sample = text[333333:333333 + 700]\n",
    "print('Исходный текст:\\n')\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Закодированное сообщение:\n",
      "\n",
      "вчхчесбюдбочйрвгрдбдзосвачдвсдъднкорвшартврджнрдщдвчьснгебщдъстбэсдвчхчесдчачэмдъдхчбмдърхрочдбэч чедлсеэсвбэгтдсйгъещщбюдгдяогдфасцдбемхчрдяорнясечжчщдхасдрцмдмнчбабщдяорнбачъгаюдмйрджсасъсрдъдржсджсесърдяочънгъсрдсягбчвгрдъбржсдасжсдхасдсвд вчедгдъгнредвсдгцярочасодмеулвмебщдгдярорлгедржсдбэсеюэсдцгеюдсаэмнчдгднсэмнчдъчшрдърегхрбаъсдсаднкорвшартвчднсдэорцбчдаогдбдясесъгвскдцгегдъчшрдърегхрбаъсдзочвым удсбачъгегдеръутдлрорждэчэднсвсбгегдеч махгэгдъдвсхюдвчдяесачьдяроряочъгегбюдясбернвгрднсбачасхвсдегдзмочйчдъдэорцбрдзмочйдврдлуеднсбачъервдъдасцдэсегхрбаърдгцярочасодярорлгедржсдъдэсасосцдхчбмдмлгаджрврочедшцгадъдбрцюдхчбсъдэчйрабщдъдхчбсъдсхрвюдярхчеювсдсхрвюдярхчеювсдгцярочасодбэч чедхасдсв\n"
     ]
    }
   ],
   "source": [
    "sample_encoded = encrypt(sample, encoder)\n",
    "print('Закодированное сообщение:\\n')\n",
    "print(sample_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Декодированное сообщение:\n",
      "\n",
      "вю со сяьш  окттаьезсноэонлгои йистквихронатчнаарлвстосаврриндбоеолвю соошуочо и к л  ил    ньоаынснауотеолоиит ксиасиося  елм  и двьдис даелт гдомдоирка о и  к  лпаррелт тпоовеяяккоатме рнааи  пмотмоорлаел озсинаа ыувн ттаиыапмож емока о оирувсн  ивинлнлго еон  у тбккисяукврр  ен т ман пмоьоеоошеосдаоя ело  н  йвго  нипеиаиллрм лпено еайистквихровнйвоестиеннжвм ьеедоорвжгеосдар ипеиаиллрм лпенозс  оруву  поовар чтлбатащ тплеачийвог чар чмыпбб зи и лганялвнемоеосжен тол оварвсяед дт ьттайв поу адгочр зкх  зни естиеаазкх  елнаацынйв пооаткии ж двееорм лпела еон  у тбен т ман пмои еее тндвк л  крмеатекн  снгедеаи ьаижяк лбр еа оьарри к лбр  а кыяен  сомго а кыяен  сомго еон  у тбьоаынснка о от\n"
     ]
    }
   ],
   "source": [
    "decoder = get_decoder(sample_encoded, get_counter_bigram, text)\n",
    "decoded_text = decode_bigram(sample_encoded, decoder)\n",
    "print('Декодированное сообщение:\\n')\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность:\n",
      "\n",
      "9.86%\n"
     ]
    }
   ],
   "source": [
    "print('Точность:\\n')\n",
    "print(f'{char_accuracy(sample, decoded_text):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size:     200     accuracy: 10.00%\n",
      "sample_size:     500     accuracy: 10.00%\n",
      "sample_size:    1500     accuracy: 15.20%\n",
      "sample_size:    3000     accuracy: 12.80%\n",
      "sample_size:    5000     accuracy: 10.04%\n",
      "sample_size:   10000     accuracy: 11.70%\n",
      "sample_size:   30000     accuracy: 14.60%\n",
      "sample_size:   50000     accuracy: 15.28%\n",
      "sample_size:  100000     accuracy: 20.03%\n",
      "sample_size:  200000     accuracy: 24.88%\n",
      "sample_size:  400000     accuracy: 38.35%\n",
      "sample_size:  642495     accuracy: 33.15%\n"
     ]
    }
   ],
   "source": [
    "for sample_size in [200, 500, 1500, 3000, 5000, 10000, 30000, 50000, 100000, 200000, 400000, 642495]:\n",
    "    \n",
    "    start_point = 123456\n",
    "    sample = text[start_point:start_point+sample_size]\n",
    "    \n",
    "    sample = re.sub(r\"[a-z]+\", \" \", sample)\n",
    "\n",
    "    sample_encoded = encrypt(sample, encoder)\n",
    "\n",
    "    decoder = get_decoder(sample_encoded, get_counter_bigram, text)\n",
    "    decoded_text = decode_bigram(sample_encoded, decoder)\n",
    "\n",
    "    acc = char_accuracy(sample, decoded_text)\n",
    "    print(f\"sample_size: {sample_size:>7}     accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность ужасная даже на всем семпле! \n",
    "\n",
    "Меня смущает, что в моей реализации для каждого символа (кроме первого и последнего) могут быть два кандидата, от выбора которых очень сильно зависит следующий текст. Я пробовал два простых варианта: пройтись циклом и каждый следующий символ считать началом новой биграммы, и другой подход - нарезать текст на непересекающиеся биграммы. Оба подхода получились одинаково плохими. \n",
    "\n",
    "Можно, наверное, как-то обучать биграммы, например, добавить условие, что мы знаем первый или второй символ этой биграммы или вообще посмотреть в сторону скрытых цепей маркова (HMM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`task 3 `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем ходить в пространстве возможных раскодированных текстов и искать такие, которые более вероятно семплированы из нашего большого корпуса. \n",
    "\n",
    "Тогда для каждой перестановки вероятность вытащить ее из нашего текста - то есть ее правдоподобие - это просто перемножение вероятностей каждой биграммы. \n",
    "\n",
    "Семплировать будем методом МСМС - двигаемся в каком-то случайном направлении и принимаем или отвергаем гипотезу в зависимости от старого и нового правдоподобия. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "\n",
      "началось сражение с фронта но в дюренштейне где я находился войско начало атаку в часу вечера сказал болконский оживляясь и при этом случае предполагая что ему удастся представить уже готовое в его голове правдивое описание всего того что он знал и видел но император улыбнулся и перебил его сколько миль откуда и докуда ваше величество от дюренштейна до кремса три с половиною мили ваше величество французы оставили левый берег как доносили лазутчики в ночь на плотах переправились последние достаточно ли фуража в кремсе фураж не был доставлен в том количестве император перебил его в котором часу убит генерал шмит в семь часов кажется в часов очень печально очень печально император сказал что он\n"
     ]
    }
   ],
   "source": [
    "sample = text[333333:333333 + 700]\n",
    "print('Исходный текст:\\n')\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Закодированное сообщение:\n",
      "\n",
      "ыжфжцмэюьэлжшиы иьэьелмыгжьымькьсалиыйгияыиьпсиьоьыжтмс цэоькмяэбмьыжфжцмьжгжбнькьфжэнькифилжьэбжвжцьумцбмыэб яьмш кцооэюь ьъл ьщгмрьэцнфжиьълисъмцжпжоьфгмьирньнсжэгэоьълисэгжк гюьншиьпмгмкмиькьипмьпмцмкиьължкс кмиьмъ эжы иькэипмьгмпмьфгмьмыьвыжць ьк сицьымь ръилжгмльнцхуынцэоь ьъилиу цьипмьэбмцюбмьр цюьмгбнсжь ьсмбнсжькжйиькиц фиэгкмьмгьсалиыйгияыжьсмьблирэжьгл ьэьъмцмк ымаьр ц ькжйиькиц фиэгкмьелжызнвхьмэгжк ц ьцикхяьуилипьбжбьсмымэ ц ьцжвнгф б ькьымфюьыжьъцмгжтьъилиължк ц эюьъмэцисы иьсмэгжгмфымьц ьенлжшжькьблирэиьенлжшьыиьухцьсмэгжкциыькьгмрьбмц фиэгкиь ръилжгмльъилиу цьипмькьбмгмлмрьфжэньну гьпиыилжцьйр гькьэирюьфжэмкьбжшигэоькьфжэмкьмфиыюьъифжцюымьмфиыюьъифжцюымь ръилжгмльэбжвжцьфгмьмы\n"
     ]
    }
   ],
   "source": [
    "sample_encoded = encrypt(sample, encoder)\n",
    "print('Закодированное сообщение:\\n')\n",
    "print(sample_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNT_BIGRAM_IN_TEXT = sum(wp_counter_bigram.values())  # 642494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_mapping(decoder, n_permutations=1):\n",
    "    new_decoder = decoder.copy()\n",
    "    for _ in range(n_permutations):\n",
    "        key_1 = random.choice(list(new_decoder.keys()))\n",
    "        key_2 = random.choice(list(new_decoder.keys()))\n",
    "        new_decoder[key_1], new_decoder[key_2] = new_decoder[key_2], new_decoder[key_1]\n",
    "    return new_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_log_likelihood(decoder):\n",
    "    decoded_text = decode(sample_encoded, decoder)\n",
    "    log_likelihood = 0\n",
    "    for idx, symbol in enumerate(decoded_text[:-1]):\n",
    "        bigram = (decoded_text[idx] + decoded_text[idx + 1])\n",
    "        bigram_proba = wp_counter_bigram.get(bigram, 1) / CNT_BIGRAM_IN_TEXT\n",
    "        log_likelihood += np.log(bigram_proba)\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_log_accept(cur_l, new_l):\n",
    "    \"\"\" mcmc approach: \n",
    "    if p(new) > p(old) then accept with probability = 1\n",
    "    if p(new) < p(old) then accept with probability = p(new) / p(old)\n",
    "    \"\"\"\n",
    "    if new_l > cur_l:\n",
    "        return True\n",
    "    else:\n",
    "        return np.random.rand() < np.exp(new_l - cur_l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(func_log_likelihood, iterations, init_decoder):\n",
    "\n",
    "    decoded_text = decode(sample_encoded, init_decoder)\n",
    "    cur_l = best_l = func_log_likelihood(init_decoder)\n",
    "    cur_decoder = best_decoder = init_decoder\n",
    "\n",
    "    success_steps = 0\n",
    "    for i in range(iterations):\n",
    "        new_decoder = get_new_mapping(cur_decoder)\n",
    "\n",
    "        new_l = func_log_likelihood(new_decoder)\n",
    "\n",
    "        if metropolis_hastings_log_accept(cur_l, new_l):\n",
    "            cur_decoder, cur_l = new_decoder, new_l\n",
    "            success_steps += 1\n",
    "            \n",
    "            if cur_l > best_l:\n",
    "                best_l = cur_l\n",
    "                best_decoder = cur_decoder\n",
    "                \n",
    "    success_rate = success_steps / iterations\n",
    "\n",
    "    return best_l, best_decoder, success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_decoder = get_decoder(sample_encoded, get_counter_unigram, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 7.94 ms, total: 2.06 s\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_l, best_decoder, sr = metropolis_hastings(func_log_likelihood, iterations=2000, init_decoder=init_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = decode(sample_encoded, best_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success steps ratio  0.05850\n",
      "char accuracy        0.92429\n",
      "\n",
      "decoded text:\n",
      "\n",
      " надалось сражение с шронта но в зюренцтейне гзе я нахозился войско надало атаку в дасу ведера скачал болконский оживляясь и при этом слудае презполагая дто ему узастся презставить уже готовое в его голове правзивое описание всего того дто он чнал и визел но император улыбнулся и перебил его сколько миль откуза и зокуза ваце велидество от зюренцтейна зо кремса три с половиною мили ваце велидество шранщучы оставили левый берег как зоносили лачутдики в нодь на плотах переправились послезние зостатодно ли шуража в кремсе шураж не был зоставлен в том колидестве император перебил его в котором дасу убит генерал цмит в семь дасов кажется в дасов одень педально одень педально император скачал дто он\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'success steps ratio  {sr:.5f}')\n",
    "print(f'char accuracy        {char_accuracy(sample, decoded_text):.5f}')\n",
    "print('\\ndecoded text:\\n\\n', decoded_text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔥✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`task 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расшифруйте сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n"
     ]
    }
   ],
   "source": [
    "sample_encoded = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'\n",
    "print(sample_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_counter = get_counter_unigram(sample_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('↹', 34), ('←', 22), ('⇛', 22), ('↟', 15), ('⇒', 13)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 34)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arrow_counter), len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_decoder = get_decoder(sample_encoded, get_counter_unigram, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': '↹',\n",
       " 'о': '←',\n",
       " 'а': '⇛',\n",
       " 'е': '↟',\n",
       " 'и': '⇒',\n",
       " 'н': '↝',\n",
       " 'т': '⇴',\n",
       " 'с': '↨',\n",
       " 'л': '⇠',\n",
       " 'в': '⇯',\n",
       " 'р': '↷',\n",
       " 'к': '⇌',\n",
       " 'д': '⇊',\n",
       " 'м': '⇞',\n",
       " 'у': '⇈',\n",
       " 'п': '⇷',\n",
       " 'я': '↤',\n",
       " 'г': '↳',\n",
       " 'ь': '↾',\n",
       " 'ы': '↙',\n",
       " 'з': '⇙',\n",
       " 'б': '↲',\n",
       " 'ч': '↞',\n",
       " 'й': '⇆',\n",
       " 'ж': '⇰',\n",
       " 'ш': '⇸',\n",
       " 'х': '↘',\n",
       " 'ю': '⇏'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.64 s, sys: 9.55 ms, total: 4.65 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_l, best_decoder, sr = metropolis_hastings(func_log_likelihood, iterations=15000, init_decoder=init_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = decode(sample_encoded, best_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success steps ratio  0.04800\n",
      "\n",
      "decoded text:\n",
      "\n",
      " если вы вимите норжальный или подти норжальный текст у чтого сообшения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обешаю\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'success steps ratio  {sr:.5f}')\n",
    "print('\\ndecoded text:\\n\\n', decoded_text[:700])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Супер) Даже не пришлось менять код =) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дожмем глазами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_decoder['д'] = '↤'\n",
    "best_decoder['м'] = '↳'\n",
    "best_decoder['ж'] = '⇸'\n",
    "best_decoder['ч'] = '⇞'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "decoded text:\n",
      "\n",
      " если вы видите нормальный или почти нормальный текст у жтого сообшения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обешаю\n"
     ]
    }
   ],
   "source": [
    "decoded_text = decode(sample_encoded, best_decoder)\n",
    "print('\\ndecoded text:\\n\\n', decoded_text[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
